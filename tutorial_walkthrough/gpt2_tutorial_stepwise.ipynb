{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeJBQvnfqTg9",
        "outputId": "53d09c96-e3aa-447a-dc9f-ac7d18d6d9fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters are: 20479\n",
            "\n",
            "First 100 characters: \n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ],
      "source": [
        "#import the dataset, we are using a book as a dataset here --> \"The verdict\"\n",
        "\n",
        "with open(\"the_verdict.txt\", \"r\", encoding = \"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "print(f\"Total number of characters are: {len(raw_text)}\\n\")\n",
        "print(\"First 100 characters: \")\n",
        "print(raw_text[:99])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the text, example:\n",
        "import re\n",
        "\n",
        "text = \"Hello, world. This is an example text.\"\n",
        "result = re.split(r'(\\s)', text)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "AZqC1UtfsU0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe389ee5-ce8a-4d2f-83d3-64cbe446504e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', ' ', 'world.', ' ', 'This', ' ', 'is', ' ', 'an', ' ', 'example', ' ', 'text.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = re.split(r'([,.]|\\s)', text)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "khzdg5E3srve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5317c8bf-9420-41ef-db61-5456c7b40341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ' ', 'is', ' ', 'an', ' ', 'example', ' ', 'text', '.', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = [item for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "id": "mhQ4KOCDsrtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa556ebc-2d99-495d-b3ff-9277cda1535f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'This', 'is', 'an', 'example', 'text', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, this is-- an example. No? yes, buddy!, though-we have, ok?\"\n",
        "\n",
        "result = re.split(r'([,:?!._\"()\\']|--|\\s)', text)\n",
        "result = [item for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "id": "sJKlSCdmsrqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee89537-a27f-4f40-dc84-4389b2e78730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'this', 'is', '--', 'an', 'example', '.', 'No', '?', 'yes', ',', 'buddy', '!', ',', 'though-we', 'have', ',', 'ok', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed = re.split(r'([,:?!._\"()\\']|--|\\s)', raw_text)\n",
        "preprocessed = [item for item in preprocessed if item.strip()]\n",
        "print(preprocessed[:30])"
      ],
      "metadata": {
        "id": "8_V7eJIasroW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f87001-809e-46ce-b922-558413aedf2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(preprocessed))"
      ],
      "metadata": {
        "id": "sa4pceP6srl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f9a868c-af17-4e39-ae14-f28a00fa6ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = sorted(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "2iw1pTW9srg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d27834-1ad4-4d42-8087-14986be6a6b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {token: integer for integer, token in enumerate(all_words)}"
      ],
      "metadata": {
        "id": "wRnxLKlC5lVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(vocab.items()):\n",
        "  print(item)\n",
        "  if i>=10:\n",
        "    break"
      ],
      "metadata": {
        "id": "CdzsS9bc5lSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a26f77-6888-4e1a-fa04-80aa68cbeb57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV1:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self, text):\n",
        "    preprocessed = re.split(r'([,:?!._\"()\\']|--|\\s)', text)\n",
        "    preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "\n",
        "    ids = [self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self, ids):\n",
        "    text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "    text = re.sub(r'\\s+([,.:;?!()\\'\"\\[\\]])', r'\\1', text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "U_oC-Ndq5lNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)\n",
        "\n",
        "text = \"\"\"It's the last he painted, you know,\"\n",
        "          Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "id": "1wFZ_scIAamp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a84fc5-9175-4391-d9d4-6d3d8ae798e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[57, 2, 861, 999, 610, 538, 754, 5, 1139, 603, 5, 1, 68, 7, 39, 862, 1121, 764, 803, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string = tokenizer.decode(ids)\n",
        "print(string)"
      ],
      "metadata": {
        "id": "giLpeXUsAa4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5468ee0-e354-49ea-a48e-251f691bee65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"hello, how are you\"\n",
        "try:\n",
        "  # The encode method expects a string as input, so this should work\n",
        "  encoded_string = tokenizer.encode(string)\n",
        "  print(f\"Encoded string: {encoded_string}\")\n",
        "except Exception as e:\n",
        "  print(f\"Error is: {e}\")"
      ],
      "metadata": {
        "id": "x2paYF1l5lIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6801cfe7-bfc0-40b1-cf43-2e1a84b645cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error is: 'hello'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = sorted(list(set(preprocessed)))\n",
        "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "\n",
        "vocab = {token : integer for integer,token in enumerate(all_tokens)}"
      ],
      "metadata": {
        "id": "zNL4DKqZ5lFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab.items())"
      ],
      "metadata": {
        "id": "xcQT1jn85k-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84b50915-9646-4fa0-b9be-e82d54c7528d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1145"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,item in enumerate(list(vocab.items())[-5:]):\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "IfZyzwu65k7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ab162c-7da2-4bd7-842b-238041f19dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('younger', 1140)\n",
            "('your', 1141)\n",
            "('yourself', 1142)\n",
            "('<|endoftext|>', 1143)\n",
            "('<|unk|>', 1144)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV2          :\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self, text):\n",
        "    preprocessed = re.split(r'([,:?!._\"()\\']|--|\\s)', text)\n",
        "    preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "    preprocessed = [\n",
        "        item if item in self.str_to_int\n",
        "        else \"<|unk|>\" for item in preprocessed\n",
        "    ]\n",
        "\n",
        "    ids = [self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self, ids):\n",
        "    text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "    text = re.sub(r'\\s+([,.:;?!()\\'\"\\[\\]])', r'\\1', text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "mx6xQ3sX5k49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV2(vocab)\n",
        "\n",
        "text1 = \"Hello, how are you?\"\n",
        "text2 = \"In the sulit terraces of the palace.\"\n",
        "\n",
        "text = \" <|endoftext|> \".join((text1, text2))\n",
        "print(text)"
      ],
      "metadata": {
        "id": "-TJQROwFZCPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d380f1-f369-4440-a133-23bb1d0f223a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, how are you? <|endoftext|> In the sulit terraces of the palace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(text)"
      ],
      "metadata": {
        "id": "BwvsyHcpZCMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c90687-6ae0-4462-9871-b5766c3c3f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1144, 5, 566, 172, 1139, 10, 1143, 56, 999, 1144, 995, 730, 999, 1144, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fVgbLPYlZCJo",
        "outputId": "0067f426-3bc6-4731-8708-f741b877316f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|unk|>, how are you? <|endoftext|> In the <|unk|> terraces of the <|unk|>.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Byte pair encoding"
      ],
      "metadata": {
        "id": "SLwjPkWpovjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZRZLsBWZCFK",
        "outputId": "b890f350-3486-4653-cb9d-2452f390cd94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "\n",
        "importlib.metadata.version(\"tiktoken\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s7g02P6cZCBA",
        "outputId": "4a2ba2d4-a150-4b38-a61b-2f27b4bc871a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.9.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "pBdltvW7ZB-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    \"Hello, how are you? <|endoftext|> In the sulit terraces of the palace.\"\n",
        "    \"of someunknowplace.\"\n",
        ")\n",
        "\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "print(integers)"
      ],
      "metadata": {
        "id": "e8R-ZDJCZB7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de3919a2-6540-4465-da91-749c3c61505c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 703, 389, 345, 30, 220, 50256, 554, 262, 33154, 270, 8812, 2114, 286, 262, 20562, 13, 1659, 617, 2954, 2197, 5372, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode = tokenizer.decode(integers)\n",
        "print(decode)"
      ],
      "metadata": {
        "id": "sWZyJTN6sspw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb411cf2-14f3-486e-ab4d-b54a04d9c7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, how are you? <|endoftext|> In the sulit terraces of the palace.of someunknowplace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Input Target Pairs"
      ],
      "metadata": {
        "id": "XR2ncX351b97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the_verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(len(enc_text))"
      ],
      "metadata": {
        "id": "PHUvKOIxssYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd44d96-7afe-4da9-a155-b1565be6d85a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_text[50:]"
      ],
      "metadata": {
        "id": "aW8KwYROtLkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 4\n",
        "\n",
        "X = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size]\n",
        "\n",
        "print(f\"X: {X}\")\n",
        "print(f\"y:      {y}\")"
      ],
      "metadata": {
        "id": "2GgLqF-WtLgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb43b8b9-f430-4cc2-ee77-7afb8bf621b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: [290, 4920, 2241, 287]\n",
            "y:      [4920, 2241, 287]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size+1):\n",
        "  input = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "\n",
        "  print(f\"{input} ---> {desired}\")"
      ],
      "metadata": {
        "id": "x6GA06ogtLcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0835e2c6-97cf-406f-8994-1e7f92436a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290] ---> 4920\n",
            "[290, 4920] ---> 2241\n",
            "[290, 4920, 2241] ---> 287\n",
            "[290, 4920, 2241, 287] ---> 257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size+1):\n",
        "  input = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "\n",
        "  print(f\"{tokenizer.decode(input)} ---> {tokenizer.decode([desired])}\")   #Note that the desired is in list, this is because the decoder is expecting a list of integers not a single integer so it even a single word has to be passed by the list\n"
      ],
      "metadata": {
        "id": "amNc-y1L6Bys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbbe20d0-1a71-404e-f218-03f0c51a2b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and --->  established\n",
            " and established --->  himself\n",
            " and established himself --->  in\n",
            " and established himself in --->  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "SFELVHiREcT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt, allowed_special = {\"<|endoftext|>\"})\n",
        "\n",
        "    for i in range(0, len(token_ids)- max_length, stride):\n",
        "      input_chunk = token_ids[i:i + max_length]\n",
        "      target_chunk = token_ids[i+1: i + max_length + 1]\n",
        "\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]\n"
      ],
      "metadata": {
        "id": "b_-hD6KY6Brh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length = 256,\n",
        "                         stride = 256, shuffle= True, drop_last = True,\n",
        "                         num_workers = 0):\n",
        "\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "  dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size = batch_size,\n",
        "      shuffle = shuffle,\n",
        "      drop_last = drop_last,\n",
        "      num_workers = num_workers\n",
        "  )\n",
        "\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "6JSNgFeVFdI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the_verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()"
      ],
      "metadata": {
        "id": "dXsHc5rwIERc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size = 1, max_length= 4, stride = 1, shuffle = False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "second_batch = next(data_iter)\n",
        "print(first_batch)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "id": "ye0qxuajFdGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e5edcc-722a-4cce-ebec-0338d2361f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n",
            "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size = 8, max_length= 4, stride = 4, shuffle = False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "\n",
        "print(f\"Inputs:\\n{inputs}\")\n",
        "print(f\"Inputs:\\n{targets}\")\n"
      ],
      "metadata": {
        "id": "vFEnPnjRFdER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41fea773-3691-47fd-de81-ca3fd2d18839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "Inputs:\n",
            "tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Embedding Tokens (Vector representation of word)"
      ],
      "metadata": {
        "id": "gL0PaZH6jmFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([2, 3, 1, 5])"
      ],
      "metadata": {
        "id": "C7T7ko6XFdB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 6\n",
        "output_dim = 3\n",
        "\n",
        "torch.manual_seed(123)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "Pnef1t3aFc_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "id": "_NHYAErWFc9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca21c06c-fdaf-413b-d645-94705b7b394c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(torch.tensor(3)))"
      ],
      "metadata": {
        "id": "gqLbyEs0Fc6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f677da-f0b9-4f1c-bd3e-a65846236714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.4015,  0.9666, -1.1481], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(input_ids))"
      ],
      "metadata": {
        "id": "4rD1B_PNlYGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73bf597-0ebe-4880-c6ef-2717be952f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [-2.8400, -0.7849, -1.4096]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional Encoding (Encoding Word Positions)"
      ],
      "metadata": {
        "id": "LxWT5UgBYATN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "vocab_size = 50257\n",
        "dimension = 256\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size,dimension)"
      ],
      "metadata": {
        "id": "P9FLn4u3lYDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size = 8, max_length = max_length,\n",
        "    stride = max_length, shuffle = False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)"
      ],
      "metadata": {
        "id": "ep7gjf7vlYBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Token IDs:\\n\", inputs)\n",
        "print(f\"Targets:\\n{targets}\")"
      ],
      "metadata": {
        "id": "_Kzd2j3glX-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db5deefc-139a-4048-d31b-e61e395f9456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "Targets:\n",
            "tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)"
      ],
      "metadata": {
        "id": "iGu6qBc_dq39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6670b461-a507-4939-b6d1-fecb3095d943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "pos_embedding_layer = nn.Embedding(context_length, dimension )"
      ],
      "metadata": {
        "id": "P7daIWq-dq1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
        "print(pos_embeddings.shape)"
      ],
      "metadata": {
        "id": "cqIYQT8pdqyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "396f8b2a-1a17-40a4-bc46-d3a1d0e21b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = token_embeddings + pos_embeddings\n",
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "id": "4-381rF7dqwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80dff10b-29de-402c-dcf4-2d0fea0f94a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementing Simplified Attention Mechanism"
      ],
      "metadata": {
        "id": "zKW-mZuVD0jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "inputs = torch.tensor(\n",
        "    [[0.43, 0.15, 0.89], # Your (x^1)\n",
        "     [0.55, 0.87, 0.66],\n",
        "     [0.57, 0.85, 0.66],\n",
        "     [0.22, 0.58, 0.33],\n",
        "     [0.77, 0.25, 0.1],\n",
        "     [0.05, 0.8 , 0.55]]\n",
        ")"
      ],
      "metadata": {
        "id": "wHqCjqoZdqtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1]\n",
        "\n",
        "attn_scores_2 = torch.empty(inputs.shape[0])\n",
        "\n",
        "for i, x_i in enumerate(inputs):\n",
        "  attn_scores_2[i] = torch.dot(x_i, query)\n",
        "\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "id": "hcZzaxRwdqri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80109a63-183f-4e4b-b507-743a10b78baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9544, 1.4950, 1.4886, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
        "\n",
        "print(\"Attention weights: \", attn_weights_2_tmp)\n",
        "print(\"Sum: \", attn_weights_2_tmp.sum())"
      ],
      "metadata": {
        "id": "GjLRbLOHdqo7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3120011b-80ab-4387-cd90-35f4a31f268f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights:  tensor([0.1452, 0.2274, 0.2264, 0.1283, 0.1075, 0.1652])\n",
            "Sum:  tensor(1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
        "\n",
        "print(\"Attention weights: \", attn_weights_2)\n",
        "print(\"Sum: \", attn_weights_2.sum())"
      ],
      "metadata": {
        "id": "tXhBY00Edql8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd8915f0-61c5-45f9-d97c-e26be6cef703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights:  tensor([0.1381, 0.2372, 0.2356, 0.1236, 0.1078, 0.1576])\n",
            "Sum:  tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after calulating the normalized attention weights for each of inputs wrt the\n",
        "query_2, now we are going to find the context vector for the query_2. And this is done by multiplying the embedded input tokens with their respective attention weights, and then summing up the resultant vector"
      ],
      "metadata": {
        "id": "pjo_foCGRCYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1]\n",
        "\n",
        "context_vec_2 = torch.zeros(query.shape)\n",
        "for i, x_i in enumerate(inputs):\n",
        "  context_vec_2 += attn_weights_2[i] * x_i\n",
        "\n",
        "print(context_vec_2)"
      ],
      "metadata": {
        "id": "taCohVUgdqjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef51a59d-aecb-47f8-cb0d-89887d5cfe81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4423, 0.6521, 0.5732])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "there are 3 steps to remember:\n",
        "(1) compute attention scores\n",
        "(2) compute attention weights\n",
        "(3) compute context vectors"
      ],
      "metadata": {
        "id": "QD1J7zHGSy7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = torch.empty(6,6)\n",
        "\n",
        "for i, x_i in enumerate(inputs):\n",
        "  for j, x_j in enumerate(inputs):\n",
        "    attn_scores[i, j] = torch.dot(x_i, x_j)\n",
        "\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "id": "IGT3OYhaTObd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4528d3d6-57ad-47ed-bcd5-cfd3f9c34603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9600, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4886, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9600, 1.4886, 1.4830, 0.8362, 0.7174, 1.0715],\n",
            "        [0.4753, 0.8434, 0.8362, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7174, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0715, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "better way is follow:"
      ],
      "metadata": {
        "id": "DOYydpS1UQDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = inputs @ inputs.T\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "id": "okGE9fz3TPAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9327c036-2a68-4798-d1bc-de77e44c739b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9600, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4886, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9600, 1.4886, 1.4830, 0.8362, 0.7174, 1.0715],\n",
            "        [0.4753, 0.8434, 0.8362, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7174, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0715, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "id": "NXP9hATQTO98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf6547c-e42a-498a-e8ec-4d1c66a68aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2091, 0.1999, 0.2010, 0.1238, 0.1216, 0.1446],\n",
            "        [0.1381, 0.2372, 0.2356, 0.1236, 0.1078, 0.1576],\n",
            "        [0.1395, 0.2366, 0.2353, 0.1232, 0.1094, 0.1559],\n",
            "        [0.1433, 0.2071, 0.2056, 0.1460, 0.1261, 0.1718],\n",
            "        [0.1526, 0.1958, 0.1978, 0.1366, 0.1878, 0.1295],\n",
            "        [0.1381, 0.2179, 0.2146, 0.1417, 0.0986, 0.1891]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_context_vecs = attn_weights @ inputs\n",
        "print(all_context_vecs )"
      ],
      "metadata": {
        "id": "-Z_pMpNtTO7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34eb7e48-8ad6-48d3-9b52-686ad390b21e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4425, 0.5940, 0.5832],\n",
            "        [0.4423, 0.6521, 0.5732],\n",
            "        [0.4434, 0.6504, 0.5730],\n",
            "        [0.4306, 0.6301, 0.5553],\n",
            "        [0.4671, 0.5911, 0.5306],\n",
            "        [0.4181, 0.6508, 0.5690]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self Attention with Trainable Weights"
      ],
      "metadata": {
        "id": "sLhQ_bFInvNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "inputs = torch.tensor(\n",
        "    [[0.43, 0.15, 0.89], # Your (x^1)\n",
        "     [0.55, 0.87, 0.66],\n",
        "     [0.57, 0.85, 0.66],\n",
        "     [0.22, 0.58, 0.33],\n",
        "     [0.77, 0.25, 0.1],\n",
        "     [0.05, 0.8 , 0.55]]\n",
        ")"
      ],
      "metadata": {
        "id": "tmGGZXqlTO5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_in = inputs.shape[1]\n",
        "d_out = 2"
      ],
      "metadata": {
        "id": "3w5N0A11TO2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad = False)\n",
        "W_keys = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad = False)\n",
        "W_values = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad = False)\n"
      ],
      "metadata": {
        "id": "HO6rcFalTO0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = inputs @ W_query\n",
        "keys = inputs @ W_keys\n",
        "values = inputs @ W_values\n",
        "\n",
        "print(f\"Queries matrix shape:{queries.shape}\\n Keys matrix shape:{keys.shape}\\n Values matrix shape:{values.shape}\")"
      ],
      "metadata": {
        "id": "-1Imf_l-TOxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0edc92f-0c10-4721-8e0b-1bcde47ac00f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Queries matrix shape:torch.Size([6, 2])\n",
            " Keys matrix shape:torch.Size([6, 2])\n",
            " Values matrix shape:torch.Size([6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to find the attention score of the query_2 we will have a dot produ t of it with the keys matrix, remember keys are the words \" your _ journy _ starts ...\""
      ],
      "metadata": {
        "id": "VP_Uez15u-Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_2 = queries[1]\n",
        "query_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX_0UPYbvkvc",
        "outputId": "6c8e05fa-7255-4b8b-d82b-2573eaa2ac39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4306, 1.4551])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores_2 = query_2 @ keys.T\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZlY0C2Zsktc",
        "outputId": "47b693e7-b685-45f7-b1ec-99525cda4263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2705, 1.8524, 1.8338, 1.0795, 0.5577, 1.5440])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = queries @ keys.T\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYwU0bqRskqz",
        "outputId": "a3ebe8a1-b41d-46fc-c1f7-7677277bc8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9231, 1.3545, 1.3406, 0.7910, 0.4032, 1.1330],\n",
            "        [1.2705, 1.8524, 1.8338, 1.0795, 0.5577, 1.5440],\n",
            "        [1.2682, 1.8489, 1.8303, 1.0774, 0.5568, 1.5409],\n",
            "        [0.6973, 1.0167, 1.0065, 0.5925, 0.3061, 0.8475],\n",
            "        [0.6114, 0.8819, 0.8735, 0.5121, 0.2707, 0.7307],\n",
            "        [0.8995, 1.3165, 1.3031, 0.7682, 0.3937, 1.0996]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we will calculate the attention weights that are normalized means that their sum will be equal to 1. But we wont directly apply the softmax here, before that we will divide the attention scores matrix by the root of the keys matrix output dimension which in this case is 2, there are 2 dimensions in the key matrix. After that we will apply the softmax function."
      ],
      "metadata": {
        "id": "lvQJCMriyzQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_k = keys.shape[-1]\n",
        "attn_weights = torch.softmax(attn_scores / d_k**0.5, dim=-1)\n",
        "attn_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhJZGcNtskmN",
        "outputId": "60a48d64-ea3d-4d5c-a8e7-aa40d3cfb8c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1547, 0.2099, 0.2079, 0.1409, 0.1071, 0.1795],\n",
              "        [0.1495, 0.2256, 0.2226, 0.1306, 0.0903, 0.1814],\n",
              "        [0.1495, 0.2255, 0.2225, 0.1307, 0.0904, 0.1814],\n",
              "        [0.1588, 0.1991, 0.1976, 0.1475, 0.1204, 0.1766],\n",
              "        [0.1608, 0.1946, 0.1935, 0.1499, 0.1263, 0.1749],\n",
              "        [0.1554, 0.2087, 0.2067, 0.1416, 0.1087, 0.1790]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector = attn_weights @ values\n",
        "context_vector"
      ],
      "metadata": {
        "id": "gWcGL7wSskj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51be82e3-fb55-4475-d218-f29584a88339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3003, 0.8092],\n",
              "        [0.3069, 0.8253],\n",
              "        [0.3069, 0.8252],\n",
              "        [0.2954, 0.7975],\n",
              "        [0.2933, 0.7926],\n",
              "        [0.2997, 0.8079]])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implement a compact version of Self Attention Class"
      ],
      "metadata": {
        "id": "2XCQPkmOM2Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "LExYCEviNRjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class SelfAttentionV1(nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
        "    self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
        "    self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
        "\n",
        "  def forward(self, x):\n",
        "    queries = x @ self.W_query\n",
        "    keys = x @ self.W_key\n",
        "    values = x @ self.W_value\n",
        "\n",
        "    attn_scores = queries @ keys.T\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores / keys.shape[-1]**0.5 , dim=-1\n",
        "    )\n",
        "\n",
        "    context_vec = attn_weights @ values\n",
        "\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "aVMG9I3nM1cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "sa_v1 = SelfAttentionV1(d_in, d_out)\n",
        "print(sa_v1(inputs))"
      ],
      "metadata": {
        "id": "0vaglXaeskhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3421d398-875b-459b-dee0-46a79be0333e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3003, 0.8092],\n",
            "        [0.3069, 0.8253],\n",
            "        [0.3069, 0.8252],\n",
            "        [0.2954, 0.7975],\n",
            "        [0.2933, 0.7926],\n",
            "        [0.2997, 0.8079]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttentionV2(nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_out, qkv_bias = False):\n",
        "    super().__init__()\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    queries = self.W_query(x)\n",
        "    keys = self.W_key(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    attn_scores = queries @ keys.T\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores / keys.shape[-1]**0.5 , dim=-1\n",
        "    )\n",
        "\n",
        "    context_vec = attn_weights @ values\n",
        "\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "DaxHLB2Hskec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(789)\n",
        "sa_v2 = SelfAttentionV2(d_in, d_out)\n",
        "print(sa_v2(inputs))"
      ],
      "metadata": {
        "id": "U325ebdeskbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e2d862-5cd6-4e11-f318-2cbf9da42244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0746,  0.0706],\n",
            "        [-0.0755,  0.0696],\n",
            "        [-0.0755,  0.0697],\n",
            "        [-0.0767,  0.0678],\n",
            "        [-0.0770,  0.0673],\n",
            "        [-0.0761,  0.0686]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hiding Future Tokens with Causal Attention"
      ],
      "metadata": {
        "id": "zXyfDTbIM2l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = sa_v2.W_query(inputs)\n",
        "keys = sa_v2.W_key(inputs)\n",
        "attn_scores = queries @ keys.T\n",
        "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5 , dim=-1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "id": "N4XlWLS6Qoa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "457e91a1-38e8-45d4-f2a4-65e1fe15fc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1920, 0.1645, 0.1657, 0.1549, 0.1720, 0.1509],\n",
            "        [0.2039, 0.1657, 0.1671, 0.1494, 0.1663, 0.1476],\n",
            "        [0.2038, 0.1657, 0.1671, 0.1495, 0.1664, 0.1476],\n",
            "        [0.1868, 0.1666, 0.1673, 0.1570, 0.1660, 0.1563],\n",
            "        [0.1830, 0.1668, 0.1674, 0.1588, 0.1657, 0.1584],\n",
            "        [0.1933, 0.1662, 0.1672, 0.1541, 0.1664, 0.1528]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = attn_scores.shape[0]\n",
        "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
        "print(mask_simple)"
      ],
      "metadata": {
        "id": "0twVo-qGQoYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b6061a-737f-44ed-a1bf-3c0a83424261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_simple = attn_weights * mask_simple\n",
        "masked_simple"
      ],
      "metadata": {
        "id": "-LLLf6C9QoV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef74cbf4-ba06-44e1-8686-a03362c5bd1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1920, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2039, 0.1657, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2038, 0.1657, 0.1671, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1868, 0.1666, 0.1673, 0.1570, 0.0000, 0.0000],\n",
              "        [0.1830, 0.1668, 0.1674, 0.1588, 0.1657, 0.0000],\n",
              "        [0.1933, 0.1662, 0.1672, 0.1541, 0.1664, 0.1528]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the problem with this is that when we have applied the softmax function to the attention scores then we have weights that are influenced from eachother. Now as we are masking other weigths that are above the diagonal in this way we are having a ***data leakeage*** problem.\n",
        "In order to avoid that, we have to apply the maske to the attention scores and then apply the softmax on that"
      ],
      "metadata": {
        "id": "eMQDVhcJQ_nE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.triu(torch.ones(context_length, context_length), diagonal =1)\n",
        "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
        "masked"
      ],
      "metadata": {
        "id": "mF6YQiB1QoSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93df15a3-13b6-4488-fca3-75638ab4fb88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
              "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
              "        [0.4634, 0.1708, 0.1825,   -inf,   -inf,   -inf],\n",
              "        [0.2642, 0.1024, 0.1087, 0.0186,   -inf,   -inf],\n",
              "        [0.2183, 0.0874, 0.0924, 0.0177, 0.0786,   -inf],\n",
              "        [0.3408, 0.1270, 0.1355, 0.0198, 0.1290, 0.0078]],\n",
              "       grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=-1)\n",
        "attn_weights"
      ],
      "metadata": {
        "id": "N6iXPmVOOwRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6737731d-1b5d-40a6-9ae8-0700744a2513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3798, 0.3088, 0.3114, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2756, 0.2458, 0.2469, 0.2317, 0.0000, 0.0000],\n",
              "        [0.2174, 0.1982, 0.1989, 0.1886, 0.1969, 0.0000],\n",
              "        [0.1933, 0.1662, 0.1672, 0.1541, 0.1664, 0.1528]],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Masking Additional Weights with Dropout"
      ],
      "metadata": {
        "id": "wEgy-vG1U1Qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "example = torch.ones(6,6)\n",
        "drop = torch.nn.Dropout(0.5)\n",
        "drop(example)"
      ],
      "metadata": {
        "id": "R-QfsBk_OwPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e339d280-b1ed-4bae-be51-044caf761af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2., 2., 2., 2.],\n",
              "        [0., 2., 0., 0., 0., 0.],\n",
              "        [0., 0., 2., 0., 2., 0.],\n",
              "        [2., 2., 0., 0., 0., 2.],\n",
              "        [2., 0., 0., 0., 0., 2.],\n",
              "        [0., 2., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "drop(attn_weights)"
      ],
      "metadata": {
        "id": "zcUiTBVXOwKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "109e243c-b23f-44d3-f2ac-e71a9730cc96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.8966, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.6228, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5512, 0.4916, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4348, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.3324, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementing the Causal Attention Class with Batches"
      ],
      "metadata": {
        "id": "MKLDRbD9X4KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "batch.shape"
      ],
      "metadata": {
        "id": "7bHsbd98OwHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88c755f-12ac-4a10-f55a-dc2ef9013f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length,\n",
        "               dropout, qkv_bias = False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(1,2)\n",
        "    attn_scores.masked_fill_(\n",
        "        self.mask.bool()[:num_tokens, :num_tokens], -torch.inf\n",
        "    )\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores / keys.shape[-1]**0.2, dim = -1\n",
        "    )\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    context_vec = attn_weights @ values\n",
        "\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "YN43IC93OwEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "context_length = batch.shape[1]\n",
        "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
        "context_vec = ca(batch)\n",
        "print(\"context_vecs.shape: \", context_vec.shape)"
      ],
      "metadata": {
        "id": "CArh9RPxYNeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb9a22f-25d5-486f-9704-d41124c41f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context_vecs.shape:  torch.Size([2, 6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implmenting Multi Head Attention Mechanism"
      ],
      "metadata": {
        "id": "fI2M-naj_E82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "6ZBMA_jZAeUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionWrapper(nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias = False):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList(\n",
        "        [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
        "        for _ in range(num_heads)]\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.cat([head(x) for head in self.heads], dim=-1)"
      ],
      "metadata": {
        "id": "3WGwNx_t_EcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor(\n",
        "    [[0.43, 0.15, 0.89], # Your (x^1)\n",
        "     [0.55, 0.87, 0.66],\n",
        "     [0.57, 0.85, 0.66],\n",
        "     [0.22, 0.58, 0.33],\n",
        "     [0.77, 0.25, 0.1],\n",
        "     [0.05, 0.8 , 0.55]]\n",
        ")\n",
        "\n",
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "batch.shape"
      ],
      "metadata": {
        "id": "TcuBH3E-YNbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc78410-f556-4640-b360-a78ea016e326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "context_length = batch.shape[1]\n",
        "d_in, d_out = 3, 2\n",
        "mha = MultiHeadAttentionWrapper(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "context_vecs = mha(batch)\n",
        "print(f\"Context vectors shape: {context_vecs.shape}\")\n",
        "context_vecs"
      ],
      "metadata": {
        "id": "v0whxHHkYNZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eed849c-784e-4cb7-80f5-8ccbacf6afba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context vectors shape: torch.Size([2, 6, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
              "         [-0.5884,  0.0042,  0.5918,  0.3310],\n",
              "         [-0.6324, -0.0621,  0.6243,  0.3899],\n",
              "         [-0.5691, -0.0829,  0.5495,  0.3601],\n",
              "         [-0.5543, -0.0967,  0.5333,  0.3431],\n",
              "         [-0.5311, -0.1072,  0.5086,  0.3504]],\n",
              "\n",
              "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
              "         [-0.5884,  0.0042,  0.5918,  0.3310],\n",
              "         [-0.6324, -0.0621,  0.6243,  0.3899],\n",
              "         [-0.5691, -0.0829,  0.5495,  0.3601],\n",
              "         [-0.5543, -0.0967,  0.5333,  0.3431],\n",
              "         [-0.5311, -0.1072,  0.5086,  0.3504]]], grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementing Multi Head Attention with Weight Splits"
      ],
      "metadata": {
        "id": "_ASBeBpMJGed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias = False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads\n",
        "\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias = qkv_bias)\n",
        "    self.out_proj = nn.Linear(d_out, d_out)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "        \"mask\",\n",
        "        torch.triu(torch.ones(context_length, context_length), diagonal =1)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch, num_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    # reshaping the keys, queries and the values matrices to include the num_heads and heads_dimensions\n",
        "    keys = keys.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
        "    values = values.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
        "    queries = queries.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "    keys = keys.transpose(1,2)\n",
        "    values = values.transpose(1,2)\n",
        "    queries = queries.transpose(1,2)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(2,3)\n",
        "\n",
        "    mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "    attn_scores = attn_scores.masked_fill(mask_bool, -torch.inf) # Corrected to masked_fill\n",
        "\n",
        "    attn_weights = torch.softmax(attn_scores/ keys.shape[-1]**0.5 , dim=-1) # Corrected power to 0.5\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    context_vecs = (attn_weights @ values).transpose(2,3)\n",
        "\n",
        "    context_vecs = context_vecs.contiguous().view(batch, num_tokens, self.d_out)\n",
        "    context_vec = self.out_proj(context_vecs)\n",
        "\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "AXuAJzW-YNWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "# define the tensor with 3 rows and 6 columns\n",
        "inputs = torch.tensor(\n",
        "    [[0.43, 0.15, 0.89, 0.45, 0.48, 0.22],\n",
        "     [0.51, 0.45, 0.49, 0.54, 0.78, 0.48],\n",
        "     [0.78, 0.25, 0.19, 0.34, 0.95, 0.18]]\n",
        ")\n",
        "\n",
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "print(batch.shape)\n",
        "\n",
        "batch_size, context_length, d_in = batch.shape\n",
        "d_out = 6\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "context_vecs = mha(batch)\n",
        "print(f\"Context vectors shape: {context_vecs.shape}\")\n",
        "context_vecs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khAYo4L5oO-h",
        "outputId": "6f40f16e-d138-4ff2-e2c5-a970c4f9c064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 6])\n",
            "Context vectors shape: torch.Size([2, 3, 6])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 5.6656e-03, -1.4075e-02, -3.2083e-01,  4.4987e-02, -2.5496e-01,\n",
              "          -2.0374e-01],\n",
              "         [ 6.9323e-02, -1.7293e-01, -1.9275e-01,  4.7439e-02, -3.2554e-01,\n",
              "          -3.1213e-01],\n",
              "         [ 3.4623e-01, -3.8212e-01, -9.8199e-06,  2.6555e-01, -5.1240e-01,\n",
              "          -3.4843e-01]],\n",
              "\n",
              "        [[ 5.6656e-03, -1.4075e-02, -3.2083e-01,  4.4987e-02, -2.5496e-01,\n",
              "          -2.0374e-01],\n",
              "         [ 6.9323e-02, -1.7293e-01, -1.9275e-01,  4.7439e-02, -3.2554e-01,\n",
              "          -3.1213e-01],\n",
              "         [ 3.4623e-01, -3.8212e-01, -9.8199e-06,  2.6555e-01, -5.1240e-01,\n",
              "          -3.4843e-01]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Layer Normalization Example"
      ],
      "metadata": {
        "id": "0X7dhA4JDE9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "torch.manual_seed(123)\n",
        "batch_example = torch.randn(2,5)\n",
        "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
        "output = layer(batch_example)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "3-_FWI8KoO7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653f51fa-ec79-473d-9d7c-4592ab05096a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
            "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = output.mean(dim=-1, keepdim=True)\n",
        "variance = output.var(dim=-1, keepdim=True)\n",
        "mean , variance"
      ],
      "metadata": {
        "id": "Z0qJuefnoO4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b409c518-745f-45e2-e52f-fc63e644e6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.1324],\n",
              "         [0.2170]], grad_fn=<MeanBackward1>),\n",
              " tensor([[0.0231],\n",
              "         [0.0398]], grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_norm = (output - mean) / torch.sqrt(variance)\n",
        "print(output_norm)\n",
        "output_norm.mean(), output_norm.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo7DMS6aFFg-",
        "outputId": "6b123313-56cb-443b-a409-3a218230022b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
            "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1.2418e-08, grad_fn=<MeanBackward0>),\n",
              " tensor(0.9091, grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets's create a layer normalization class"
      ],
      "metadata": {
        "id": "H0ZV-uhSF00q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True)\n",
        "    var = x.var(dim=-1, keepdim=True, unbiased = False)\n",
        "    norm_x = (x - mean) / torch.sqrt(var + self.eps)        # self.eps to avoid the divison by zero\n",
        "    return self.scale * norm_x + self.shift"
      ],
      "metadata": {
        "id": "PA0OgDF5FFcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ln = LayerNorm(emb_dim=5)\n",
        "out_ln = ln(batch_example)\n",
        "out_ln.mean(dim=-1, keepdim=True), out_ln.var(dim=-1, keepdim=True, unbiased = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hro5KoPqFFRD",
        "outputId": "91a7ba85-5264-4a0d-f8d4-858f741f2475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-2.9802e-08],\n",
              "         [ 0.0000e+00]], grad_fn=<MeanBackward1>),\n",
              " tensor([[1.0000],\n",
              "         [1.0000]], grad_fn=<VarBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feed Forward Neural Network with GeLU Activation Function"
      ],
      "metadata": {
        "id": "9I8YFdUh6h5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return 0.5 * x * (1 + torch.tanh(\n",
        "        torch.sqrt(torch.tensor(2.0/torch.pi)) *\n",
        "        (x + 0.044715 * torch.pow(x, 3))\n",
        "    ))"
      ],
      "metadata": {
        "id": "npq0iUG36hwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"num_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"dropout\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}"
      ],
      "metadata": {
        "id": "oSi4gixp-vOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "        GELU(),\n",
        "        nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "GPFMkStNWTDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ffn = FeedForward(GPT_CONFIG_124M)\n",
        "x = torch.randn(2, 3, 768)\n",
        "out = ffn(x)\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONl0Tf4j_XlT",
        "outputId": "37673e54-160c-408a-9ff5-e532d367bd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Shortcut Connections"
      ],
      "metadata": {
        "id": "H0c9LBCI8DmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "8Mfv9ZJf8o5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExampleDeepNeuralNetwork(nn.Module):\n",
        "  def __init__(self, layer_sizes, use_shortcut):\n",
        "    super().__init__()\n",
        "    self.use_shortcut = use_shortcut\n",
        "    self.layers = nn.ModuleList([\n",
        "        nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
        "        nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
        "        nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
        "        nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
        "        nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
        "    ])\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      layer_output = layer(x)\n",
        "\n",
        "      if self.use_shortcut and x.shape == layer_output.shape:\n",
        "        x = x + layer_output\n",
        "\n",
        "      else:\n",
        "        x = layer_output\n",
        "    return x"
      ],
      "metadata": {
        "id": "mE7R-Uh7_Xig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers_size = [3,3,3,3,3,1]\n",
        "sample_input = torch.tensor([1., 0., -1.])\n",
        "torch.manual_seed(123)\n",
        "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
        "    layer_sizes = layers_size, use_shortcut = False\n",
        ")"
      ],
      "metadata": {
        "id": "RxMkNx8L_XdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_gradient(model, x):\n",
        "  output = model(x)\n",
        "  target = torch.tensor([[0.]])\n",
        "\n",
        "  loss = nn.MSELoss()\n",
        "  loss = loss(output, target)\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  for name, param in model.named_parameters():\n",
        "    if 'weight' in name:\n",
        "      print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
      ],
      "metadata": {
        "id": "Dsj0dzL68HtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_gradient(model_without_shortcut, sample_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgKnhSW68Hqq",
        "outputId": "88a724d0-80c5-4e7f-b856-cdb4f24b41c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight has gradient mean of 0.00020173584925942123\n",
            "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
            "layers.2.0.weight has gradient mean of 0.0007152040489017963\n",
            "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
            "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
        "    layer_sizes = layers_size, use_shortcut = True\n",
        ")\n",
        "print_gradient(model_with_shortcut, sample_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJZ2suJr8Hnw",
        "outputId": "782ebb2f-baab-4a89-b6ac-e3e591ce5e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
            "layers.1.0.weight has gradient mean of 0.20694108307361603\n",
            "layers.2.0.weight has gradient mean of 0.3289699852466583\n",
            "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
            "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CODING THE ENTIRE TRANFORMER BLOCK\n"
      ],
      "metadata": {
        "id": "M1Dy-P8RMay6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"num_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}"
      ],
      "metadata": {
        "id": "2sasJI2d8HlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The building Blocks: Layer Normalization, GELU and Feed Forward Neural Networks"
      ],
      "metadata": {
        "id": "25qONf1wMjix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True)\n",
        "    var = x.var(dim=-1, keepdim=True, unbiased = False)\n",
        "    norm_x = (x - mean) / torch.sqrt(var + self.eps)        # self.eps to avoid the divison by zero\n",
        "    return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return 0.5 * x * (1 + torch.tanh(\n",
        "        torch.sqrt(torch.tensor(2.0/torch.pi)) *\n",
        "        (x + 0.044715 * torch.pow(x, 3))\n",
        "    ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "        GELU(),\n",
        "        nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "GF7qLEQYGc9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.attn = MultiHeadAttention(\n",
        "        d_in = cfg[\"emb_dim\"],\n",
        "        d_out = cfg[\"emb_dim\"],\n",
        "        context_length = cfg[\"context_length\"],\n",
        "        num_heads = cfg[\"num_heads\"],\n",
        "        dropout = cfg[\"drop_rate\"],\n",
        "        qkv_bias = cfg[\"qkv_bias\"]\n",
        "    )\n",
        "    self.ff = FeedForward(cfg)\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "     short_cut = x\n",
        "     x = self.norm1(x)\n",
        "     x = self.attn(x)\n",
        "     x = self.drop_shortcut(x)\n",
        "     x = x + short_cut\n",
        "\n",
        "     x = self.norm2(x)\n",
        "     x = self.ff(x)\n",
        "     x = self.drop_shortcut(x)\n",
        "     x = x + short_cut\n",
        "\n",
        "     return x"
      ],
      "metadata": {
        "id": "n_zvjrPUGc7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "input = torch.randn(2,4,768)\n",
        "block = TransformerBlock(GPT_CONFIG_124M)\n",
        "output = block(input)\n",
        "\n",
        "print(f\"Input shape: {input.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwwNH7G8Gc4f",
        "outputId": "6c47108a-23ef-4eed-9643-5948bd0f7819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GPT Architecture: Entire GPT Model Architecture Implementation"
      ],
      "metadata": {
        "id": "2jwyeMb-aVO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "3AA11aoJakdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"num_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}"
      ],
      "metadata": {
        "id": "1K75pkGiGc1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True)\n",
        "    var = x.var(dim=-1, keepdim=True, unbiased = False)\n",
        "    norm_x = (x - mean) / torch.sqrt(var + self.eps)        # self.eps to avoid the divison by zero\n",
        "    return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return 0.5 * x * (1 + torch.tanh(\n",
        "        torch.sqrt(torch.tensor(2.0/torch.pi)) *\n",
        "        (x + 0.044715 * torch.pow(x, 3))\n",
        "    ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "        GELU(),\n",
        "        nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "TuOLljh1NsHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.attn = MultiHeadAttention(\n",
        "        d_in = cfg[\"emb_dim\"],\n",
        "        d_out = cfg[\"emb_dim\"],\n",
        "        context_length = cfg[\"context_length\"],\n",
        "        num_heads = cfg[\"num_heads\"],\n",
        "        dropout = cfg[\"drop_rate\"],\n",
        "        qkv_bias = cfg[\"qkv_bias\"]\n",
        "    )\n",
        "    self.ff = FeedForward(cfg)\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "     short_cut = x\n",
        "     x = self.norm1(x)\n",
        "     x = self.attn(x)\n",
        "     x = self.drop_shortcut(x)\n",
        "     x = x + short_cut\n",
        "\n",
        "     x = self.norm2(x)\n",
        "     x = self.ff(x)\n",
        "     x = self.drop_shortcut(x)\n",
        "     x = x + short_cut\n",
        "\n",
        "     return x"
      ],
      "metadata": {
        "id": "n1Zrm_PiNsEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "        *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "    )\n",
        "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(\n",
        "        cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False\n",
        "    )\n",
        "\n",
        "  def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(torch.arange(seq_len, device = in_idx.device))\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x)\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "l-gvrPhobHGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "input = torch.tensor(\n",
        "    [[6109, 3268, 4500, 1540],\n",
        "     [4842, 7835, 1498, 6471]]\n",
        ")\n",
        "\n",
        "out = model(input)\n",
        "print(f\"Input Shape: {input.shape}\")\n",
        "print(input)\n",
        "print(f\"Ouptput Shape: {out.shape}\")\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFcmJO5ebHDt",
        "outputId": "1157ae4a-ed5f-4926-a284-ea5579ce6f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Shape: torch.Size([2, 4])\n",
            "tensor([[6109, 3268, 4500, 1540],\n",
            "        [4842, 7835, 1498, 6471]])\n",
            "Ouptput Shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[-0.5180,  0.0160, -0.2312,  ..., -0.0733, -0.4553, -0.1522],\n",
            "         [ 0.5978, -0.2561,  0.1821,  ..., -0.0275, -0.7868,  0.2548],\n",
            "         [ 1.4565,  0.6167,  0.2669,  ...,  0.3947, -1.2181, -0.0225],\n",
            "         [-0.4758,  0.5908,  0.3407,  ...,  1.0671, -0.5460, -0.2400]],\n",
            "\n",
            "        [[-0.1350, -0.8241, -0.2631,  ...,  0.4139,  0.0175, -0.2412],\n",
            "         [ 0.2777,  0.7263,  0.5468,  ..., -0.2329,  0.1099,  0.1082],\n",
            "         [ 1.3276,  0.9659, -0.3130,  ...,  0.1762, -0.5293, -0.7593],\n",
            "         [-0.0903, -0.2821, -0.3516,  ...,  0.1754,  0.0062, -0.4687]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"The number of parameters are: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w6_1G2egYhp",
        "outputId": "791ee77e-7e78-4dd7-b38c-790fb3c749d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of parameters are: 163,009,536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate Text from the Output Tokens"
      ],
      "metadata": {
        "id": "K2WAc6b3wUFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "\n",
        "  for _ in range(max_new_tokens):\n",
        "\n",
        "    idx = idx[:, -context_size:]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx)\n",
        "\n",
        "    logits = logits[:, -1, :]\n",
        "\n",
        "    probas = torch.softmax(logits, dim=-1)\n",
        "\n",
        "    idx_next = torch.argmax(probas, dim=-1, keepdim= True)\n",
        "\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "  return idx"
      ],
      "metadata": {
        "id": "ZpPyc6C0gYfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_context = \"Hello, I am\"\n",
        "encoded = tokenizer.encode(start_context)\n",
        "print(\"encoded:\", encoded)\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "print(\"encoded_tensor_shape:\",encoded_tensor.shape)"
      ],
      "metadata": {
        "id": "X6HRjsmegYcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc3a692-8d6c-4ab1-95df-b3bd78769bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded: [15496, 11, 314, 716]\n",
            "encoded_tensor_shape: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "out = generate_text_simple(\n",
        "    model = model,\n",
        "    idx = encoded_tensor,\n",
        "    max_new_tokens = 6,\n",
        "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output:\", out)\n",
        "print(\"Output length:\", len(out[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkh6UtDZ0vRc",
        "outputId": "90b7fc3e-aee7-42b9-c17e-061eaddbeb58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
            "Output length: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ8KC-wG0vOS",
        "outputId": "1e716e90-69dc-49ee-ee52-7c764105071b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am Featureiman Byeswickattribute argue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using GPT to Generate Text"
      ],
      "metadata": {
        "id": "c1KBh2UYkZQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 256,\n",
        "    \"emb_dim\": 768,\n",
        "    \"num_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "G51H_Lc6YP4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Ouput text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "SNeRw8-VYP1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a69d8b0-9c57-4fa5-e1e7-c48067bfaea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ouput text:\n",
            " Every effort moves you Laur inhab overd facto yakMobilfifth durANG stren\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],\n",
        "                       [   40, 1107,  588]])\n",
        "\n",
        "targets = torch.tensor([[ 3626, 6100,  345],\n",
        "                        [ 1107,  588, 11311]])\n"
      ],
      "metadata": {
        "id": "PKMOcpJgYPym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  logits = model(inputs)\n",
        "\n",
        "probas = torch.softmax(logits, dim=-1)\n",
        "print(probas.shape)"
      ],
      "metadata": {
        "id": "QjZMVxfYYPv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c2cc467-da08-4fba-9fb0-425db75c4df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = torch.argmax(probas, dim=-1, keepdim= True)\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ],
      "metadata": {
        "id": "i_lobnCfYPsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d22804b-e593-4584-a076-17f9de05fa19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[43756],\n",
            "         [16031],\n",
            "         [42826]],\n",
            "\n",
            "        [[48671],\n",
            "         [16031],\n",
            "         [23689]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calculating Cross Entropy"
      ],
      "metadata": {
        "id": "T2sJjIpawupu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_idx = 0\n",
        "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 1:\", target_probas_1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probas_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdES7dAXmS1W",
        "outputId": "9921aa3f-1edd-4e21-d566-17c9d73a3089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([4.3073e-05, 2.1773e-05, 1.2470e-05])\n",
            "Text 2: tensor([1.2868e-05, 3.8498e-05, 4.7689e-06])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3llS0CIbmSy1",
        "outputId": "0aea06c9-adc3-44ee-d210-a7c07f56ac9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-10.0526, -10.7349, -11.2922, -11.2608, -10.1649, -12.2534])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIlaVosMmSwB",
        "outputId": "d1f953cf-8f16-419f-a1fc-1028013dc55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10.9598)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2bQdVNUmStG",
        "outputId": "939a217c-1be6-4f8e-acab-1f87dd78e6ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.9598)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "or a simpler one liner code, to find the cross entropy"
      ],
      "metadata": {
        "id": "j6YvBT34xHUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits_flat = logits.flatten(0,1)\n",
        "targets_flat = targets.flatten(0,1)"
      ],
      "metadata": {
        "id": "D9PPtQVrx9pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR5heysfxM2U",
        "outputId": "0c3030ba-48f7-4d41-eddc-0df6f96e5d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.9598)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = torch.exp(loss)\n",
        "perplexity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMosdiJ-xM0O",
        "outputId": "4939638e-4528-4f1f-c44d-f4f9f52f514d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(57514.2656)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "file_path = \"the_verdict.txt\"\n",
        "url = \"https://github.com/rasbt/LLMs-from-scratch/blob/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        text_data = response.read().decode('utf-8')\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text_data)\n",
        "else:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text_data = file.read()\n"
      ],
      "metadata": {
        "id": "MIfcr_doxMx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_data[:100])"
      ],
      "metadata": {
        "id": "767oeOJ6xMvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8880146a-6926-4a6b-9cbe-2f8c3321519c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "total_tokens"
      ],
      "metadata": {
        "id": "_vEcp_SuxMs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e68ac383-3480-456c-9d60-c1f350a448d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5145"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 256,\n",
        "    \"emb_dim\": 768,\n",
        "    \"num_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}"
      ],
      "metadata": {
        "id": "7cMU-6_CYkUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt, allowed_special = {\"<|endoftext|>\"})\n",
        "\n",
        "    for i in range(0, len(token_ids)- max_length, stride):\n",
        "      input_chunk = token_ids[i:i + max_length]\n",
        "      target_chunk = token_ids[i+1: i + max_length + 1]\n",
        "\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length = 256,\n",
        "                         stride = 256, shuffle= True, drop_last = True,\n",
        "                         num_workers = 0):\n",
        "\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "  dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size = batch_size,\n",
        "      shuffle = shuffle,\n",
        "      drop_last = drop_last,\n",
        "      num_workers = num_workers\n",
        "  )\n",
        "\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "83xezbMfxMqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]"
      ],
      "metadata": {
        "id": "ZgAeonk7dZpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size = 2,\n",
        "    max_length = GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride = GPT_CONFIG_124M[\"context_length\"],\n",
        "    shuffle= True,\n",
        "    drop_last = True,\n",
        "    num_workers = 0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size = 2,\n",
        "    max_length = GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride = GPT_CONFIG_124M[\"context_length\"],\n",
        "    shuffle= False,\n",
        "    drop_last = False,\n",
        "    num_workers = 0\n",
        ")"
      ],
      "metadata": {
        "id": "zOVLVNNVdZmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "  print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        "  print(x.shape, y.shape)\n",
        "\n",
        "print(len(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3eaZThcdZj-",
        "outputId": "8b43f3d1-d6cd-4cad-efcc-25a1d86e3338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "        *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "    )\n",
        "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(\n",
        "        cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False\n",
        "    )\n",
        "\n",
        "  def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(torch.arange(seq_len, device = in_idx.device))\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x)\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "\n",
        "    return logits\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)"
      ],
      "metadata": {
        "id": "pg3lPRPVdZhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "  input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "  logits = model(input_batch)\n",
        "  loss = nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
        "  return loss\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "  total_loss = 0.\n",
        "  if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "  return total_loss / num_batches"
      ],
      "metadata": {
        "id": "NLBlo2zzdZeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else\"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNHM9C3edZbg",
        "outputId": "304d0977-7016-463a-9d10-887458639e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_loader, model, device)\n",
        "  val_loss = calc_loss_loader(val_loader, model, device)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQI2YV3TdZY4",
        "outputId": "c7d06a27-b313-44b5-80cb-e0381b82a709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.990112834506565\n",
            "Validation loss: 10.983633995056152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Traning Loop for the LLM"
      ],
      "metadata": {
        "id": "xKEY8W_0jHQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "\n",
        "  train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "  tokens_seen, global_step = 0, -1\n",
        "\n",
        "  for epochs in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      tokens_seen += input_batch.numel()\n",
        "      global_step += 1\n",
        "\n",
        "      if (global_step % eval_freq) == 0:\n",
        "        train_loss, val_loss = evaluate_model(\n",
        "            model, train_loader, val_loader, device, eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_losses)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(f\"Epoch: {epochs+1} | Step: {global_step:06d} | Train loss: {train_loss:.3f} | Val_loss: {val_loss:.3f}\")\n",
        "\n",
        "    generate_and_print_sample(\n",
        "        model, tokenizer, device, start_context\n",
        "    )\n",
        "\n",
        "  return train_losses, val_losses, track_tokens_seen\n"
      ],
      "metadata": {
        "id": "wnBY2E_XdZWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "\n",
        "  model.train()\n",
        "  return train_loss, val_loss"
      ],
      "metadata": {
        "id": "JjxUsY4vdZTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()\n"
      ],
      "metadata": {
        "id": "tXo7YyOkdZQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Note:\n",
        "# Uncomment the following code to show the execution time\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n"
      ],
      "metadata": {
        "id": "_hWLCqmWdZN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21622d36-1fab-47bd-b5ea-06fa956b2750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | Step: 000000 | Train loss: 9.928 | Val_loss: 10.074\n",
            "Epoch: 1 | Step: 000005 | Train loss: 7.910 | Val_loss: 8.270\n",
            "Every effort moves you,.                                                \n",
            "Epoch: 2 | Step: 000010 | Train loss: 6.463 | Val_loss: 7.000\n",
            "Epoch: 2 | Step: 000015 | Train loss: 5.854 | Val_loss: 6.548\n",
            "Every effort moves you, and, and a.          \", and, and, and, and, and, and the, and the, and, and the, and, and, and the, and, and,\n",
            "Epoch: 3 | Step: 000020 | Train loss: 5.056 | Val_loss: 6.401\n",
            "Epoch: 3 | Step: 000025 | Train loss: 4.268 | Val_loss: 6.330\n",
            "Every effort moves you know the picture.                                              \n",
            "Epoch: 4 | Step: 000030 | Train loss: 3.730 | Val_loss: 6.235\n",
            "Epoch: 4 | Step: 000035 | Train loss: 3.326 | Val_loss: 6.212\n",
            "Every effort moves you know the first, and the picture for a smile that, and in a little of the picture--his--and here are the her to my the moment--as Jack himself at my dear, I had the fact of the, and he had been\n",
            "Epoch: 5 | Step: 000040 | Train loss: 2.580 | Val_loss: 6.229\n",
            "Every effort moves you know it was not that he was not to the end of the fact of a and he was no he had been.        He placed them at my elbow and as his pictures--his--because he had always his\n",
            "Epoch: 6 | Step: 000045 | Train loss: 2.159 | Val_loss: 6.220\n",
            "Epoch: 6 | Step: 000050 | Train loss: 1.617 | Val_loss: 6.286\n",
            "Every effort moves you know; and in a little: \"strong he had been the frame. I could have given Miss Croft the fact, and Mrs.  \"--as Jack himself at my elbow and as his painting.       \n",
            "Epoch: 7 | Step: 000055 | Train loss: 1.419 | Val_loss: 6.293\n",
            "Epoch: 7 | Step: 000060 | Train loss: 0.879 | Val_loss: 6.307\n",
            "Every effort moves you know; and my surprise, one of the deep arm-chairs forward. \"There: make yourself comfortable--and here are the cigars you like.\"  He placed them at the donkey--the quality of Jack's \"There were days, I\n",
            "Epoch: 8 | Step: 000065 | Train loss: 0.588 | Val_loss: 6.365\n",
            "Epoch: 8 | Step: 000070 | Train loss: 0.436 | Val_loss: 6.410\n",
            "Every effort moves you?\"         I told Mrs.           He laughed again. Gisburn's open countenance. The picture. Gisburn's \"strongest,\" was.\n",
            "Epoch: 9 | Step: 000075 | Train loss: 0.276 | Val_loss: 6.449\n",
            "Epoch: 9 | Step: 000080 | Train loss: 0.175 | Val_loss: 6.593\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the fact with equanimity.        Mrs. It was just because she was _not_ interesting--if I saw that, my--because he didn't want\n",
            "Epoch: 10 | Step: 000085 | Train loss: 0.107 | Val_loss: 6.644\n",
            "Every effort moves you?\"     I glanced after him, struck by his last word. Victor Grindle was, one longed to cry out: \"Be dissatisfied with your leisure!\" as once one had longed to say: \"Be dissatisfied with your\n",
            "Training completed in 0.65 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "nISsLdIvsYq3",
        "outputId": "931a5f2d-9a39-4382-eb42-680bc372bc14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-345013398.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mepochs_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mplot_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_seen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-345013398.py\u001b[0m in \u001b[0;36mplot_losses\u001b[0;34m(epochs_seen, tokens_seen, train_losses, val_losses)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Plot training and validation loss against epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_seen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_seen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"-.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/cbook.py\u001b[0m in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m             len(x.shape) < 1):\n\u001b[0;32m-> 1358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/shape_base.py\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "mjJJ-GMNsYkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67baeb2-1f05-49a0-caa6-f47cf676c4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\n",
        "    \"closer\": 0,\n",
        "    \"every\": 1,\n",
        "    \"effort\": 2,\n",
        "    \"forward\": 3,\n",
        "    \"inches\": 4,\n",
        "    \"moves\": 5,\n",
        "    \"pizza\": 6,\n",
        "    \"toward\": 7,\n",
        "    \"you\": 8\n",
        "}\n",
        "\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}"
      ],
      "metadata": {
        "id": "-b-HGnWiuYlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_token_logits = torch.tensor(\n",
        "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")\n"
      ],
      "metadata": {
        "id": "GSfdgCHbuYiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "print(probas)\n",
        "\n",
        "next_token_id = probas.argmax(probas).item()\n",
        "print(next_token_id)\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "id": "RF5wg2bFuYe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "9e4f98d8-50a8-4102-d56c-aa41d9f1913f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
            "        1.0120e-04, 3.5758e-01, 4.0122e-03])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "argmax(): argument 'dim' (position 1) must be int, not Tensor",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2339307513.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnext_token_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverse_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_token_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: argmax(): argument 'dim' (position 1) must be int, not Tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to implement a probabilistic sampling process, we will replace the softmax with the multinomial function"
      ],
      "metadata": {
        "id": "_EzN6SYHp4_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "next_token_id = torch.multinomial(probas, num_samples =1).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnGtD7iAp4jH",
        "outputId": "a75c3631-b3b2-4d8a-8a38-a949b446e2d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to see the effect of the multinomial function lets repeat the implementation for 1000 times"
      ],
      "metadata": {
        "id": "OttTXaVhqgYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_sampled_tokens(probas):\n",
        "    torch.manual_seed(123)  # Manual seed for reproducibility\n",
        "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1000)]\n",
        "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
        "    for i, freq in enumerate(sampled_ids):\n",
        "        print(f\"{freq} × {inverse_vocab[i]}\")\n",
        "\n",
        "print_sampled_tokens(probas)\n"
      ],
      "metadata": {
        "id": "py7zZZevacDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a86c063-a663-4007-e480-29933d0b05a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71 × closer\n",
            "2 × every\n",
            "0 × effort\n",
            "544 × forward\n",
            "2 × inches\n",
            "1 × moves\n",
            "0 × pizza\n",
            "376 × toward\n",
            "4 × you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        "    scaled_logits = logits / temperature\n",
        "    return torch.softmax(scaled_logits, dim=0)\n",
        "\n",
        "# Temperature values\n",
        "temperatures = [1, 0.1, 5] # Original, higher confidence, and lower confidence\n",
        "\n",
        "# Calculate scaled probabilities\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
      ],
      "metadata": {
        "id": "ZL_dyaYTabqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "for i, T in enumerate(temperatures):\n",
        "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
        "\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"temperature_plot.pdf\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "McJn69UGabTL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "038135b7-d26e-497a-9e87-dc32bb82a4cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'temperatures' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2466150025.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemperatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbar_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_probas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbar_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Temperature = {T}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'temperatures' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAAEYCAYAAADPvfYMAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGHVJREFUeJzt3X9s1PXhx/FXW+gVIi24rtfSnXbgEBWh2EpXkBCXm00wdfyx2AmhXQMypDPKZRPKj1ZkUuaQNJFiA+r0D1lxBoyRpgyrxCBdiIUmOvkRLNrOeAed444VbaH3/v5hOL+Vgv0cba/yfj6S+4O37/fd+96pPv0cd704Y4wRAACWio/1BgAAiCVCCACwGiEEAFiNEAIArEYIAQBWI4QAAKsRQgCA1QghAMBqhBAAYDVCCACwmuMQvvfeeyosLNT48eMVFxenN95443vX7N+/X3fddZdcLpduueUWvfzyy1FsFQCAgec4hJ2dnZo2bZpqamr6Nf/UqVO6//77de+996qlpUWPP/64Fi9erL179zreLAAAAy3uWn7pdlxcnHbv3q158+Zdcc6KFSu0Z88effTRR5Gx3/zmNzp79qwaGhqifWgAAAbEiMF+gKamJnm93l5jBQUFevzxx6+4pqurS11dXZE/h8Nhffnll/rRj36kuLi4wdoqAGAYM8bo3LlzGj9+vOLjB+4tLoMeQr/fL7fb3WvM7XYrFArpq6++0qhRoy5bU1VVpXXr1g321gAAP0Dt7e36yU9+MmD3N+ghjEZ5ebl8Pl/kz8FgUDfddJPa29uVnJwcw50BAGIlFArJ4/FozJgxA3q/gx7C9PR0BQKBXmOBQEDJycl9Xg1Kksvlksvlumw8OTmZEAKA5Qb6r8gG/XOE+fn5amxs7DW2b98+5efnD/ZDAwDwvRyH8H//+59aWlrU0tIi6ZuPR7S0tKitrU3SNy9rFhcXR+YvXbpUra2teuKJJ3Ts2DFt3bpVr732mpYvXz4wzwAAgGvgOIQffPCBpk+frunTp0uSfD6fpk+froqKCknSF198EYmiJP30pz/Vnj17tG/fPk2bNk3PPvusXnjhBRUUFAzQUwAAIHrX9DnCoRIKhZSSkqJgMMjfEQKApQarBfyuUQCA1QghAMBqhBAAYDVCCACwGiEEAFiNEAIArEYIAQBWI4QAAKsRQgCA1QghAMBqhBAAYDVCCACwGiEEAFiNEAIArEYIAQBWI4QAAKsRQgCA1QghAMBqhBAAYDVCCACwGiEEAFiNEAIArEYIAQBWI4QAAKsRQgCA1QghAMBqhBAAYDVCCACwGiEEAFiNEAIArEYIAQBWI4QAAKsRQgCA1QghAMBqhBAAYLWoQlhTU6OsrCwlJSUpLy9Phw4duur86upq3XrrrRo1apQ8Ho+WL1+ur7/+OqoNAwAwkByHcOfOnfL5fKqsrNThw4c1bdo0FRQU6PTp033O37Fjh1auXKnKykodPXpUL774onbu3KlVq1Zd8+YBALhWjkO4efNmPfzwwyotLdXtt9+u2tpajR49Wi+99FKf8w8ePKhZs2Zp/vz5ysrK0n333aeHHnroe68iAQAYCo5C2N3drebmZnm93m/vID5eXq9XTU1Nfa6ZOXOmmpubI+FrbW1VfX295s6de8XH6erqUigU6nUDAGAwjHAyuaOjQz09PXK73b3G3W63jh071uea+fPnq6OjQ/fcc4+MMbp48aKWLl161ZdGq6qqtG7dOidbAwAgKoP+rtH9+/drw4YN2rp1qw4fPqxdu3Zpz549Wr9+/RXXlJeXKxgMRm7t7e2DvU0AgKUcXRGmpqYqISFBgUCg13ggEFB6enqfa9auXauFCxdq8eLFkqQ777xTnZ2dWrJkiVavXq34+Mtb7HK55HK5nGwNAICoOLoiTExMVE5OjhobGyNj4XBYjY2Nys/P73PN+fPnL4tdQkKCJMkY43S/AAAMKEdXhJLk8/lUUlKi3NxczZgxQ9XV1ers7FRpaakkqbi4WJmZmaqqqpIkFRYWavPmzZo+fbry8vJ08uRJrV27VoWFhZEgAgAQK45DWFRUpDNnzqiiokJ+v1/Z2dlqaGiIvIGmra2t1xXgmjVrFBcXpzVr1ujzzz/Xj3/8YxUWFurpp58euGcBAECU4swP4PXJUCiklJQUBYNBJScnx3o7AIAYGKwW8LtGAQBWI4QAAKsRQgCA1QghAMBqhBAAYDVCCACwGiEEAFiNEAIArEYIAQBWI4QAAKsRQgCA1QghAMBqhBAAYDVCCACwGiEEAFiNEAIArEYIAQBWI4QAAKsRQgCA1QghAMBqhBAAYDVCCACwGiEEAFiNEAIArEYIAQBWI4QAAKsRQgCA1QghAMBqhBAAYDVCCACwGiEEAFiNEAIArEYIAQBWI4QAAKsRQgCA1aIKYU1NjbKyspSUlKS8vDwdOnToqvPPnj2rsrIyZWRkyOVyadKkSaqvr49qwwAADKQRThfs3LlTPp9PtbW1ysvLU3V1tQoKCnT8+HGlpaVdNr+7u1u//OUvlZaWptdff12ZmZn67LPPNHbs2IHYPwAA1yTOGGOcLMjLy9Pdd9+tLVu2SJLC4bA8Ho8effRRrVy58rL5tbW1+stf/qJjx45p5MiRUW0yFAopJSVFwWBQycnJUd0HAOCHbbBa4Oil0e7ubjU3N8vr9X57B/Hx8nq9ampq6nPNm2++qfz8fJWVlcntdmvKlCnasGGDenp6rm3nAAAMAEcvjXZ0dKinp0dut7vXuNvt1rFjx/pc09raqnfeeUcLFixQfX29Tp48qWXLlunChQuqrKzsc01XV5e6uroifw6FQk62CQBAvw36u0bD4bDS0tK0bds25eTkqKioSKtXr1Ztbe0V11RVVSklJSVy83g8g71NAIClHIUwNTVVCQkJCgQCvcYDgYDS09P7XJORkaFJkyYpISEhMnbbbbfJ7/eru7u7zzXl5eUKBoORW3t7u5NtAgDQb45CmJiYqJycHDU2NkbGwuGwGhsblZ+f3+eaWbNm6eTJkwqHw5GxEydOKCMjQ4mJiX2ucblcSk5O7nUDAGAwOH5p1Ofzafv27XrllVd09OhRPfLII+rs7FRpaakkqbi4WOXl5ZH5jzzyiL788ks99thjOnHihPbs2aMNGzaorKxs4J4FAABRcvw5wqKiIp05c0YVFRXy+/3Kzs5WQ0ND5A00bW1tio//tq8ej0d79+7V8uXLNXXqVGVmZuqxxx7TihUrBu5ZAAAQJcefI4wFPkcIABgWnyMEAOB6QwgBAFYjhAAAqxFCAIDVCCEAwGqEEABgNUIIALAaIQQAWI0QAgCsRggBAFYjhAAAqxFCAIDVCCEAwGqEEABgNUIIALAaIQQAWI0QAgCsRggBAFYjhAAAqxFCAIDVCCEAwGqEEABgNUIIALAaIQQAWI0QAgCsRggBAFYjhAAAqxFCAIDVCCEAwGqEEABgNUIIALAaIQQAWI0QAgCsRggBAFYjhAAAqxFCAIDVogphTU2NsrKylJSUpLy8PB06dKhf6+rq6hQXF6d58+ZF87AAAAw4xyHcuXOnfD6fKisrdfjwYU2bNk0FBQU6ffr0Vdd9+umn+sMf/qDZs2dHvVkAAAaa4xBu3rxZDz/8sEpLS3X77bertrZWo0eP1ksvvXTFNT09PVqwYIHWrVunCRMmXNOGAQAYSI5C2N3drebmZnm93m/vID5eXq9XTU1NV1z31FNPKS0tTYsWLerX43R1dSkUCvW6AQAwGByFsKOjQz09PXK73b3G3W63/H5/n2sOHDigF198Udu3b+/341RVVSklJSVy83g8TrYJAEC/Deq7Rs+dO6eFCxdq+/btSk1N7fe68vJyBYPByK29vX0QdwkAsNkIJ5NTU1OVkJCgQCDQazwQCCg9Pf2y+Z988ok+/fRTFRYWRsbC4fA3DzxihI4fP66JEydets7lcsnlcjnZGgAAUXF0RZiYmKicnBw1NjZGxsLhsBobG5Wfn3/Z/MmTJ+vDDz9US0tL5PbAAw/o3nvvVUtLCy95AgBiztEVoST5fD6VlJQoNzdXM2bMUHV1tTo7O1VaWipJKi4uVmZmpqqqqpSUlKQpU6b0Wj927FhJumwcAIBYcBzCoqIinTlzRhUVFfL7/crOzlZDQ0PkDTRtbW2Kj+cX1gAAfhjijDEm1pv4PqFQSCkpKQoGg0pOTo71dgAAMTBYLeDSDQBgNUIIALAaIQQAWI0QAgCsRggBAFYjhAAAqxFCAIDVCCEAwGqEEABgNUIIALAaIQQAWI0QAgCsRggBAFYjhAAAqxFCAIDVCCEAwGqEEABgNUIIALAaIQQAWI0QAgCsRggBAFYjhAAAqxFCAIDVCCEAwGqEEABgNUIIALAaIQQAWI0QAgCsRggBAFYjhAAAqxFCAIDVCCEAwGqEEABgNUIIALAaIQQAWC2qENbU1CgrK0tJSUnKy8vToUOHrjh3+/btmj17tsaNG6dx48bJ6/VedT4AAEPJcQh37twpn8+nyspKHT58WNOmTVNBQYFOnz7d5/z9+/froYce0rvvvqumpiZ5PB7dd999+vzzz6958wAAXKs4Y4xxsiAvL0933323tmzZIkkKh8PyeDx69NFHtXLlyu9d39PTo3HjxmnLli0qLi7u12OGQiGlpKQoGAwqOTnZyXYBANeJwWqBoyvC7u5uNTc3y+v1fnsH8fHyer1qamrq132cP39eFy5c0I033njFOV1dXQqFQr1uAAAMBkch7OjoUE9Pj9xud69xt9stv9/fr/tYsWKFxo8f3yum31VVVaWUlJTIzePxONkmAAD9NqTvGt24caPq6uq0e/duJSUlXXFeeXm5gsFg5Nbe3j6EuwQA2GSEk8mpqalKSEhQIBDoNR4IBJSenn7VtZs2bdLGjRv19ttva+rUqVed63K55HK5nGwNAICoOLoiTExMVE5OjhobGyNj4XBYjY2Nys/Pv+K6Z555RuvXr1dDQ4Nyc3Oj3y0AAAPM0RWhJPl8PpWUlCg3N1czZsxQdXW1Ojs7VVpaKkkqLi5WZmamqqqqJEl//vOfVVFRoR07digrKyvyd4k33HCDbrjhhgF8KgAAOOc4hEVFRTpz5owqKirk9/uVnZ2thoaGyBto2traFB//7YXm888/r+7ubv3617/udT+VlZV68sknr233AABcI8efI4wFPkcIABgWnyMEAOB6QwgBAFYjhAAAqxFCAIDVCCEAwGqEEABgNUIIALAaIQQAWI0QAgCsRggBAFYjhAAAqxFCAIDVCCEAwGqEEABgNUIIALAaIQQAWI0QAgCsRggBAFYjhAAAqxFCAIDVCCEAwGqEEABgNUIIALAaIQQAWI0QAgCsRggBAFYjhAAAqxFCAIDVCCEAwGqEEABgNUIIALAaIQQAWI0QAgCsRggBAFYjhAAAq0UVwpqaGmVlZSkpKUl5eXk6dOjQVef//e9/1+TJk5WUlKQ777xT9fX1UW0WAICB5jiEO3fulM/nU2VlpQ4fPqxp06apoKBAp0+f7nP+wYMH9dBDD2nRokU6cuSI5s2bp3nz5umjjz665s0DAHCt4owxxsmCvLw83X333dqyZYskKRwOy+Px6NFHH9XKlSsvm19UVKTOzk699dZbkbGf//znys7OVm1tbb8eMxQKKSUlRcFgUMnJyU62CwC4TgxWC0Y4mdzd3a3m5maVl5dHxuLj4+X1etXU1NTnmqamJvl8vl5jBQUFeuONN674OF1dXerq6or8ORgMSvrmEAAAdrrUAIfXb9/LUQg7OjrU09Mjt9vda9ztduvYsWN9rvH7/X3O9/v9V3ycqqoqrVu37rJxj8fjZLsAgOvQf/7zH6WkpAzY/TkK4VApLy/vdRV59uxZ3XzzzWpraxvQJ389C4VC8ng8am9v5+VkBzg35ziz6HBuzgWDQd1000268cYbB/R+HYUwNTVVCQkJCgQCvcYDgYDS09P7XJOenu5oviS5XC65XK7LxlNSUviBcSg5OZkziwLn5hxnFh3Ozbn4+IH95J+je0tMTFROTo4aGxsjY+FwWI2NjcrPz+9zTX5+fq/5krRv374rzgcAYCg5fmnU5/OppKREubm5mjFjhqqrq9XZ2anS0lJJUnFxsTIzM1VVVSVJeuyxxzRnzhw9++yzuv/++1VXV6cPPvhA27ZtG9hnAgBAFByHsKioSGfOnFFFRYX8fr+ys7PV0NAQeUNMW1tbr8vWmTNnaseOHVqzZo1WrVqln/3sZ3rjjTc0ZcqUfj+my+VSZWVlny+Xom+cWXQ4N+c4s+hwbs4N1pk5/hwhAADXE37XKADAaoQQAGA1QggAsBohBABYbdiEkK92cs7JmW3fvl2zZ8/WuHHjNG7cOHm93u894+uV05+1S+rq6hQXF6d58+YN7gaHIadndvbsWZWVlSkjI0Mul0uTJk3i39F+nFt1dbVuvfVWjRo1Sh6PR8uXL9fXX389RLuNvffee0+FhYUaP3684uLirvo7qS/Zv3+/7rrrLrlcLt1yyy16+eWXnT+wGQbq6upMYmKieemll8y//vUv8/DDD5uxY8eaQCDQ5/z333/fJCQkmGeeecZ8/PHHZs2aNWbkyJHmww8/HOKdx47TM5s/f76pqakxR44cMUePHjW//e1vTUpKivn3v/89xDuPLafndsmpU6dMZmammT17tvnVr341NJsdJpyeWVdXl8nNzTVz5841Bw4cMKdOnTL79+83LS0tQ7zz2HJ6bq+++qpxuVzm1VdfNadOnTJ79+41GRkZZvny5UO889ipr683q1evNrt27TKSzO7du686v7W11YwePdr4fD7z8ccfm+eee84kJCSYhoYGR487LEI4Y8YMU1ZWFvlzT0+PGT9+vKmqqupz/oMPPmjuv//+XmN5eXnmd7/73aDuczhxembfdfHiRTNmzBjzyiuvDNYWh6Vozu3ixYtm5syZ5oUXXjAlJSXWhdDpmT3//PNmwoQJpru7e6i2OCw5PbeysjLzi1/8oteYz+czs2bNGtR9Dlf9CeETTzxh7rjjjl5jRUVFpqCgwNFjxfyl0Utf7eT1eiNj/flqp/8/X/rmq52uNP96E82Zfdf58+d14cKFAf/ltcNZtOf21FNPKS0tTYsWLRqKbQ4r0ZzZm2++qfz8fJWVlcntdmvKlCnasGGDenp6hmrbMRfNuc2cOVPNzc2Rl09bW1tVX1+vuXPnDsmef4gGqgUx//aJofpqp+tJNGf2XStWrND48eMv+yG6nkVzbgcOHNCLL76olpaWIdjh8BPNmbW2tuqdd97RggULVF9fr5MnT2rZsmW6cOGCKisrh2LbMRfNuc2fP18dHR265557ZIzRxYsXtXTpUq1atWootvyDdKUWhEIhffXVVxo1alS/7ifmV4QYehs3blRdXZ12796tpKSkWG9n2Dp37pwWLlyo7du3KzU1Ndbb+cEIh8NKS0vTtm3blJOTo6KiIq1evVq1tbWx3tqwtn//fm3YsEFbt27V4cOHtWvXLu3Zs0fr16+P9dauezG/Ihyqr3a6nkRzZpds2rRJGzdu1Ntvv62pU6cO5jaHHafn9sknn+jTTz9VYWFhZCwcDkuSRowYoePHj2vixImDu+kYi+ZnLSMjQyNHjlRCQkJk7LbbbpPf71d3d7cSExMHdc/DQTTntnbtWi1cuFCLFy+WJN15553q7OzUkiVLtHr16gH/6qHrwZVakJyc3O+rQWkYXBHy1U7ORXNmkvTMM89o/fr1amhoUG5u7lBsdVhxem6TJ0/Whx9+qJaWlsjtgQce0L333quWlhZ5PJ6h3H5MRPOzNmvWLJ08eTLyPw2SdOLECWVkZFgRQSm6czt//vxlsbv0PxOGXwndpwFrgbP38QyOuro643K5zMsvv2w+/vhjs2TJEjN27Fjj9/uNMcYsXLjQrFy5MjL//fffNyNGjDCbNm0yR48eNZWVlVZ+fMLJmW3cuNEkJiaa119/3XzxxReR27lz52L1FGLC6bl9l43vGnV6Zm1tbWbMmDHm97//vTl+/Lh56623TFpamvnTn/4Uq6cQE07PrbKy0owZM8b87W9/M62treYf//iHmThxonnwwQdj9RSG3Llz58yRI0fMkSNHjCSzefNmc+TIEfPZZ58ZY4xZuXKlWbhwYWT+pY9P/PGPfzRHjx41NTU1P9yPTxhjzHPPPWduuukmk5iYaGbMmGH++c9/Rv7ZnDlzTElJSa/5r732mpk0aZJJTEw0d9xxh9mzZ88Q7zj2nJzZzTffbCRddqusrBz6jceY05+1/8/GEBrj/MwOHjxo8vLyjMvlMhMmTDBPP/20uXjx4hDvOvacnNuFCxfMk08+aSZOnGiSkpKMx+Mxy5YtM//973+HfuMx8u677/b536lL51RSUmLmzJlz2Zrs7GyTmJhoJkyYYP761786fly+hgkAYLWY/x0hAACxRAgBAFYjhAAAqxFCAIDVCCEAwGqEEABgNUIIALAaIQQAWI0QAgCsRggBAFYjhAAAqxFCAIDV/g+C7PdCuhaEqwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_token_logits2 = next_token_logits / 0.1\n",
        "print(torch.softmax(next_token_logits2, dim=0))"
      ],
      "metadata": {
        "id": "Ij9zcHRaaa-g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe4c66c-c548-4208-9d32-fa120a567ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.8530e-10, 3.5189e-26, 2.6890e-38, 9.9099e-01, 5.7569e-23, 4.4220e-37,\n",
            "        2.9718e-38, 9.0133e-03, 2.8514e-22])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_token_logits2 = next_token_logits / 5\n",
        "print(torch.softmax(next_token_logits2, dim=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWqY16Patwsg",
        "outputId": "417bdb81-9fed-4311-ab53-82484fafe108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Top-K Sampling"
      ],
      "metadata": {
        "id": "jcET_-K60Jsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 3\n",
        "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
        "print(\"Top logits:\", top_logits)\n",
        "print(\"Top positions:\", top_pos)"
      ],
      "metadata": {
        "id": "W9zescvoaa4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36882b54-b26d-4a91-ff4f-8dce32011692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
            "Top positions: tensor([3, 7, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_logits = torch.where(\n",
        "    condition=next_token_logits < top_logits[-1],\n",
        "    input=torch.tensor(float(\"-inf\")),\n",
        "    other=next_token_logits\n",
        ")\n",
        "\n",
        "print(new_logits)"
      ],
      "metadata": {
        "id": "0xvz94mxtwJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26501709-a692-4ad5-d4ae-8212916b44cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk_probas = torch.softmax(new_logits, dim=0)\n",
        "print(topk_probas)"
      ],
      "metadata": {
        "id": "yn0b19ALtu7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c77a09f-c8fe-4ea3-9939-e0df7363da36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "rDrTFaxitvmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "    top_k=25,\n",
        "    temperature=1.4\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "_5woV06YtuNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f55879-01ea-4682-ff8b-d067de3b4fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you know began to happen. It was not it was no struck by holding it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading and Saving Model Weights in Pytorch"
      ],
      "metadata": {
        "id": "rQ5nuz2S_DzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "torch.save(model.state_dict(), \"model.pth\")"
      ],
      "metadata": {
        "id": "8C5xtV6Qttqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only = False))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "SNBu344LttJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75442e3f-603c-478c-f5a3-3535bd150543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "saving the optimizer too bro!"
      ],
      "metadata": {
        "id": "WdkDpFuxBMDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay =0.1)\n",
        "\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    },\n",
        "    \"model_and_optimizer.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "B4WDTXl_tsrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay =0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train()"
      ],
      "metadata": {
        "id": "mBGdGymrtskn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb98ec77-29e2-4ea2-df00-c5bf9914bbd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00SVkzlkUlDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ia8qwhdJUkrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ilGoq6XTUkSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ilRYegErUj3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "geeid9nJUjd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mWUhJFYqMSNu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
