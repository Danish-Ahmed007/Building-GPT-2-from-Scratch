{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bdc825",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab70dcc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Access the text data from the TinyStories dataset splits and join them into single strings\n",
    "train_text_data_str = \" <|endoftext|> \".join(ds['train']['text'])\n",
    "val_text_data_str = \" <|endoftext|> \".join(ds['validation']['text'])\n",
    "\n",
    "\n",
    "# Create dataloaders using the text data from TinyStories\n",
    "train_loader_tinystories = create_dataloader_v1(\n",
    "    train_text_data_str,\n",
    "    batch_size=4, # Use context_length as batch_size for demonstration\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0 # Adjust num_workers based on your environment\n",
    ")\n",
    "\n",
    "val_loader_tinystories = create_dataloader_v1(\n",
    "    val_text_data_str,\n",
    "    batch_size=4, # Use context_length as batch_size for demonstration\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0 # Adjust num_workers based on your environment\n",
    ")\n",
    "\n",
    "print(\"TinyStories Train loader batches:\", len(train_loader_tinystories))\n",
    "print(\"TinyStories Validation loader batches:\", len(val_loader_tinystories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d0b12",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Train loader:\")\n",
    "for i, (x, y) in enumerate(train_loader_tinystories):\n",
    "  print(x.shape, y.shape)\n",
    "  if i == 5:\n",
    "        break\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for i, (x, y) in enumerate(val_loader_tinystories):\n",
    "  print(x.shape, y.shape)\n",
    "  if i == 5:\n",
    "        break\n",
    "\n",
    "print(f\"Number of batches in train_stories: {len(train_loader_tinystories)}\")\n",
    "print(f\"Number of batches in validation_stories: {len(val_loader_tinystories)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb565ba1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "  train_loss = calc_loss_loader(train_loader_tinystories, model, device)\n",
    "  val_loss = calc_loss_loader(val_loader_tinystories, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700c473f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "  \n",
    "  train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "  tokens_seen, global_step = 0, -1\n",
    "\n",
    "  for epochs in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for input_batch, target_batch in train_loader:\n",
    "      optimizer.zero_grad()\n",
    "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      tokens_seen += input_batch.numel()\n",
    "      global_step += 1\n",
    "\n",
    "      if (global_step % eval_freq) == 0:\n",
    "        train_loss, val_loss = evaluate_model(\n",
    "            model, train_loader, val_loader, device, eval_iter)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)  # Fixed: was val_losses.append(val_losses)\n",
    "        track_tokens_seen.append(tokens_seen)\n",
    "        print(f\"Epoch: {epochs+1} | Step: {global_step:06d} | Train loss: {train_loss:.3f} | Val_loss: {val_loss:.3f}\")\n",
    "    \n",
    "    generate_and_print_sample(\n",
    "        model, tokenizer, device, start_context\n",
    "    )\n",
    "  \n",
    "  return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608dd05c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "  \n",
    "  model.train()\n",
    "  return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29512e43",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
